{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy-loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Downloading numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/28.1 MB 3.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.6/28.1 MB 3.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 3.1/28.1 MB 3.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 3.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.5/28.1 MB 3.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.2/28.1 MB 3.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.8/28.1 MB 3.5 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.6/28.1 MB 3.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 3.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 8.1/28.1 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.9/28.1 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 9.7/28.1 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 10.5/28.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 11.3/28.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 12.3/28.1 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 13.1/28.1 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.9/28.1 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.9/28.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 15.5/28.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.5/28.1 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 17.3/28.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 18.1/28.1 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.1/28.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 19.9/28.1 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 20.7/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.5/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 22.3/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.8/28.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.3/28.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.0/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy-loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 soundfile-0.12.1 soxr-0.5.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting peft\n",
      "  Using cached peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (4.44.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (4.66.4)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Using cached accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from peft) (0.24.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.13.0->peft) (70.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dana\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Using cached peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Using cached accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.1.1 peft-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa\n",
    "%pip install pydub\n",
    "%pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 주요 라이브러리\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from pydub import AudioSegment\n",
    "from peft import PromptEncoder, PromptEncoderConfig\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class JSONAudioDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)[\"data\"]\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        audio_path = sample[\"audio_file\"]\n",
    "        text_condition = f\"{sample['description']} Keywords: {', '.join(sample['keywords'])}. Moods: {', '.join(sample['moods'])}.\"\n",
    "        audio = self.load_audio(audio_path)\n",
    "        return audio, text_condition\n",
    "\n",
    "    def load_audio(self, path):\n",
    "        if path.endswith(\".mp3\"):\n",
    "            wav_path = path.replace(\".mp3\", \".wav\")\n",
    "            if not os.path.exists(wav_path):\n",
    "                self.convert_mp3_to_wav(path, wav_path)\n",
    "            path = wav_path\n",
    "        try:\n",
    "            audio, _ = librosa.load(path, sr=32000)\n",
    "            return torch.tensor(audio)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio file {path}: {e}\")\n",
    "            return torch.zeros(1)\n",
    "\n",
    "    def convert_mp3_to_wav(self, mp3_path, wav_path):\n",
    "        try:\n",
    "            audio = AudioSegment.from_mp3(mp3_path)\n",
    "            audio.export(wav_path, format=\"wav\")\n",
    "            print(f\"Converted {mp3_path} to {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {mp3_path} to WAV: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT 프롬프트 조건 공급자 정의\n",
    "class PEFTPConditionProvider(torch.nn.Module):\n",
    "    def __init__(self, prompt_length, hidden_size, num_transformer_submodules, num_attention_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.config = PromptEncoderConfig(\n",
    "            task_type=\"TEXT_GENERATION\",\n",
    "            num_virtual_tokens=prompt_length,\n",
    "            token_dim=hidden_size,\n",
    "            encoder_hidden_size=hidden_size,\n",
    "            encoder_num_layers=2,\n",
    "            encoder_dropout=0.1,\n",
    "            num_transformer_submodules=num_transformer_submodules\n",
    "        )\n",
    "        self.prompt_encoder = PromptEncoder(self.config)\n",
    "        self.num_virtual_tokens = prompt_length\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        batch_size = tokens.size(0)\n",
    "        indices = torch.arange(self.num_virtual_tokens, device=tokens.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        prompt_embeds = self.prompt_encoder(indices)\n",
    "        if len(prompt_embeds.shape) == 4:\n",
    "            prompt_embeds = prompt_embeds.squeeze(0)\n",
    "        return torch.cat([prompt_embeds, tokens], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프 정의\n",
    "def train_model(model, tokenizer, dataloader, device, epochs, grad_acc_steps, lr, checkpoint_dir):\n",
    "    optimizer = AdamW(\n",
    "        list(model.lm.parameters()) + list(model.condition_provider.parameters()), \n",
    "        lr=lr\n",
    "    )\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    model.lm.train()\n",
    "    model.condition_provider.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (audio, text) in enumerate(dataloader):\n",
    "            audio = audio.to(device)\n",
    "            text_tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "            prompts = model.condition_provider(text_tokens)\n",
    "\n",
    "            num_codebooks = model.lm.num_codebooks\n",
    "            hidden_size = model.lm.embedding_dim if hasattr(model.lm, \"embedding_dim\") else 768\n",
    "            audio = audio.unsqueeze(1).expand(-1, num_codebooks, -1).to(torch.long)\n",
    "\n",
    "            try:\n",
    "                outputs = model.lm(audio, prompts)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during training: {e}\")\n",
    "                raise e\n",
    "\n",
    "            loss = loss_fn(outputs, audio)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            if (i + 1) % grad_acc_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.lm.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음악 생성 함수 정의\n",
    "def generate_music(model, tokenizer, text_condition, device, output_path):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer(text_condition, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    tokens = tokenized.input_ids.to(device)\n",
    "    prompts = model.condition_provider(tokens)\n",
    "    with torch.no_grad():\n",
    "        generated_audio = model.generate(prompts)\n",
    "    sf.write(output_path, generated_audio.cpu().numpy(), samplerate=32000)\n",
    "    print(f\"Generated music saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'audiocraft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m PROMPT_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      9\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudiocraft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MusicGen\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m MusicGen\u001b[38;5;241m.\u001b[39mget_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'audiocraft'"
     ]
    }
   ],
   "source": [
    "# 주요 실행 코드\n",
    "JSON_PATH = \"data/Silent-Night.json\"\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "GRAD_ACC_STEPS = 1\n",
    "LR = 1e-4\n",
    "PROMPT_LENGTH = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from audiocraft.models import MusicGen\n",
    "\n",
    "model = MusicGen.get_pretrained(\"small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "prompt_provider = PEFTPConditionProvider(\n",
    "    prompt_length=PROMPT_LENGTH,\n",
    "    hidden_size=768,\n",
    "    num_transformer_submodules=12,\n",
    "    num_attention_heads=12,\n",
    "    num_layers=12,\n",
    ")\n",
    "model.condition_provider = prompt_provider\n",
    "model.lm = model.lm.to(DEVICE)\n",
    "model.condition_provider = model.condition_provider.to(DEVICE)\n",
    "\n",
    "dataset = JSONAudioDataset(JSON_PATH)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_model(model, tokenizer, dataloader, DEVICE, EPOCHS, GRAD_ACC_STEPS, LR, CHECKPOINT_DIR)\n",
    "\n",
    "generate_music(model, tokenizer, \"A warm and cozy winter melody.\", DEVICE, \"generated_music.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
